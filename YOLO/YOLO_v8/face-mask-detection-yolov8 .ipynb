{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"_uuid":"7e7b0c94-7c7d-4971-942a-f66c236705e7","_cell_guid":"0ca7e5cd-0d27-4c1d-a842-7e753ea16ea4","trusted":true}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nimport shutil\nimport glob\nimport yaml\nimport torch\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as ET\nimport cv2\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom matplotlib import patches\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"4a73f811-55b2-4a4b-a2bd-562bba9550e4","_cell_guid":"3227d4e3-4e36-4156-9f4c-f68e9122ffb8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install YOLOv8","metadata":{"_uuid":"7d79913a-952a-4ab5-851f-4bc6e8571197","_cell_guid":"e2e2b98c-a87b-4244-ac84-3f094adb4ed4","trusted":true}},{"cell_type":"code","source":"","metadata":{"_uuid":"827469c7-9c00-4633-88bf-53823239f876","_cell_guid":"7f811edb-a2b8-4e99-a398-32e84b9cec43","collapsed":false,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ultralytics\nfrom ultralytics import YOLO\nultralytics.checks()","metadata":{"_uuid":"951db30d-ff64-4df4-acc3-18d872dbe118","_cell_guid":"9a7c1b23-d069-448f-914a-99bec13c9c02","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Directory","metadata":{"_uuid":"059a418e-7d1e-45ac-a4bc-cb3ac23d4f83","_cell_guid":"35ec8dd6-cbb2-4035-b4b5-7bd9904dc8c8","trusted":true}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data = \"/kaggle/input/face-mask-detection\"\nimage_directory = data + \"/images\"\nannotation_directory = data + \"/annotations\"\nannotations = list(Path(annotation_directory).glob(r'**/*{}'.format('xml')))","metadata":{"_uuid":"7b5bad56-90b9-43c4-8948-b8b55420d865","_cell_guid":"9bc4b745-e93a-4588-9cdb-16607f0a5605","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"_uuid":"51cee396-0eff-4f3f-bbf3-01160f24fe05","_cell_guid":"d9c57a99-c962-4bfb-8022-070b6b946ae3","trusted":true}},{"cell_type":"code","source":"class_id = {\n    \"with_mask\" : 0,\n    \"mask_weared_incorrect\" : 1,\n    \"without_mask\" : 2\n}\n\ndata_dict = {\n    'filename': [],\n    'label': [],\n    'class_id': [],\n    'width': [],\n    'height': [],\n    'bboxes': []\n}\nfor annotation_path in annotations:\n    tree = ET.parse(annotation_path)\n    root = tree.getroot()\n    filename = root.find('filename').text\n    for obj in root.findall(\"object\"):\n        label = obj.find(\"name\").text\n        \n        bbox = []\n        # bndbox has xmin, ymin, xmax, ymax\n        bndbox_tree = obj.find('bndbox')\n        bbox.append(int(bndbox_tree.find('xmin').text))\n        bbox.append(int(bndbox_tree.find('ymin').text))\n        bbox.append(int(bndbox_tree.find('xmax').text))\n        bbox.append(int(bndbox_tree.find('ymax').text))\n        size = root.find('size')\n        \n        data_dict['filename'].append(filename)\n        data_dict['width'].append(int(size.find('width').text))\n        data_dict['height'].append(int(size.find('height').text))\n        data_dict['label'].append(label)\n        data_dict['class_id'].append(class_id[label])\n        data_dict['bboxes'].append(bbox)\n\ndf_data = pd.DataFrame(data_dict)\n\ndf_data.head()","metadata":{"_uuid":"1396adc4-ede8-455d-8a7d-8fd581b523c5","_cell_guid":"2079291f-df4f-4037-9f02-e09670d7ee68","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data.isna().sum()","metadata":{"_uuid":"82bb87d5-5946-4efb-840a-a89b06eb4d13","_cell_guid":"d3fe4c86-e72e-4e92-823c-02e1c5382c7f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data.info()","metadata":{"_uuid":"cc59b83b-8367-4287-9445-7cd143c3b885","_cell_guid":"8f241707-3fd9-4f28-8787-9b33b9d149ec","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data.label.unique()","metadata":{"_uuid":"40c26bf6-1dfc-43ec-969c-03bf39d7a374","_cell_guid":"75d2c235-c4ae-428b-af80-4a2f03904fd5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total 'without_mask' labels: {sum(df_data.label == 'without_mask')}\")\nprint(f\"Total 'mask_weared_incorrect' labels: {sum(df_data.label == 'mask_weared_incorrect')}\")\nprint(f\"Total 'with_mask' labels: {sum(df_data.label == 'with_mask')}\")","metadata":{"_uuid":"9a599203-a43d-4845-87c4-aedb7ccc9956","_cell_guid":"74c94cd8-2adf-455d-b68b-3e0d65f6b8b3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Data","metadata":{"_uuid":"8755ea43-fd8c-474b-95a6-f69401a60354","_cell_guid":"8847e068-c6b5-411d-af15-8d271eec7b7f","trusted":true}},{"cell_type":"code","source":"def show_random_images_with_bbox(df):\n    all_images = os.listdir(image_directory)\n    random_image_filename = random.sample(all_images, 4)\n    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n    for i, filename in enumerate(random_image_filename):\n        selected_df = df[df['filename'] == filename]\n        \n        image = Image.open(image_directory + '/' + filename)\n        \n        ax.flat[i].imshow(image)\n        ax.flat[i].axis(False)\n        \n        image_bboxes = []\n        for df_index in range(0, len(selected_df)):\n            color = \"g\"\n            if selected_df.iloc[df_index].class_id == 1: color = \"y\"\n            elif selected_df.iloc[df_index].class_id == 2: color = \"r\"\n            \n            x_min, y_min, x_max, y_max = selected_df.iloc[df_index].bboxes\n            \n            rect = patches.Rectangle([x_min, y_min], x_max-x_min, y_max-y_min, \n                             linewidth=2, edgecolor=color, facecolor=\"none\")\n            ax.flat[i].add_patch(rect)\n            \nshow_random_images_with_bbox(df_data)","metadata":{"_uuid":"084d1256-e4e3-4616-a80b-2dcf6adb5bd1","_cell_guid":"329f9402-2057-4b66-9007-a47b2def8174","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the pascal voc to yolo bbox before building the model\ndef pascal_voc_to_yolo_bbox(bbox_array, w, h):\n    x_min, y_min, x_max, y_max = bbox_array\n    \n    x_center = ((x_max + x_min) / 2) / w\n    y_center = ((y_max + y_min) / 2) / h\n    \n    width = (x_max - x_min) / w\n    height = (y_max - y_min) / h\n    \n    return [x_center, y_center, width, height]","metadata":{"_uuid":"08de6277-b1fc-49cc-ab3c-17aaf778b589","_cell_guid":"2fcc16d3-1ccd-4135-8802-85d7ff38895c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Train, Val, Test images","metadata":{"_uuid":"ce71a150-d392-4614-b70d-efedd47600a6","_cell_guid":"863a293c-0d8b-49ce-9c8a-a237acce8479","trusted":true}},{"cell_type":"markdown","source":"Creating a new directory to store the images","metadata":{"_uuid":"6464d34f-b929-4232-bc0c-43d7e9ccc416","_cell_guid":"f697da1b-e698-4ce6-b76e-69e09c16ad01","trusted":true}},{"cell_type":"code","source":"tr_path = \"/kaggle/working/datasets/train\"\nval_path = \"/kaggle/working/datasets/valid\"\ntest_path = \"/kaggle/working/datasets/test\"\n\nos.mkdir(\"/kaggle/working/datasets\")\nos.mkdir(tr_path)\nos.mkdir(val_path)\nos.mkdir(test_path)","metadata":{"_uuid":"44e3bfd5-8ddf-46f6-aedd-a19a53bc4406","_cell_guid":"12d71ea4-fde7-4cd8-a502-26d3a5216f1d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Moving the images to their respective paths and create corresponding labels","metadata":{"_uuid":"4d3e1e89-2577-4aeb-b58c-69e07bdf2d8e","_cell_guid":"c25198fe-8ae4-4ff4-a004-80b868586622","trusted":true}},{"cell_type":"code","source":"train, test = train_test_split(df_data.filename.unique(), test_size=0.2, random_state=23)\ntrain, valid = train_test_split(train, test_size=0.15, random_state=23)\n\ndef copy_image_file(image_items, folder_name):\n    for image in image_items:\n            image_path = image_directory + \"/\" + image\n            new_image_path = os.path.join(folder_name, image)\n            shutil.copy(image_path, new_image_path)\n\ndef create_label_file(image_items, folder_name):\n    for image in image_items:\n        fileName = Path(image).stem\n        df = df_data[df_data['filename'] == image]\n        with open(folder_name + \"/\" + fileName +'.txt', 'w') as f:\n            for i in range(0, len(df)):\n                bbox = pascal_voc_to_yolo_bbox(df.iloc[i]['bboxes'], df.iloc[i]['width'], df.iloc[i]['height'])\n                bbox_text = \" \".join(map(str, bbox))\n                txt = str(df.iloc[i]['class_id'])+ \" \" + bbox_text\n                f.write(txt)\n                if i != len(df) - 1:\n                    f.write(\"\\n\")\n                \n\ncopy_image_file(train, train_path)\ncopy_image_file(valid, valid_path)\ncopy_image_file(test, test_path)\n\ncreate_label_file(train, train_path)\ncreate_label_file(valid, valid_path)\ncreate_label_file(test, test_path)","metadata":{"_uuid":"afe95ddb-655a-459b-b4b6-628d5c5a45f7","_cell_guid":"bee233a8-4ae0-41c2-82df-331417e75804","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def walk_through_dir(filepath):\n    for dirpath, dirnames, filenames in os.walk(filepath):\n        print(f\"There are {len(dirnames)} directories and {len(glob.glob(filepath + '/*.png', recursive = True))} images in '{dirpath}'.\")\n    \nwalk_through_dir(train_path)\nwalk_through_dir(valid_path)  \nwalk_through_dir(test_path)","metadata":{"_uuid":"b88bcfd9-beb4-4be7-864b-551987e027ed","_cell_guid":"678c9320-0775-4866-adb8-0ab7575097c5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create YAML file","metadata":{"_uuid":"a8e6d1a2-efe4-4b27-9edf-5bc776725aa4","_cell_guid":"537485d6-c400-438b-bee6-b2aeb116f32a","trusted":true}},{"cell_type":"code","source":"classes = list(df_data.label.unique())\nclass_count = len(classes)\nfacemask_yaml = f\"\"\"\n    train: train\n    val: valid\n    test: test\n    nc: {class_count}\n    names:\n        0 : with_mask\n        1 : mask_weared_incorrect\n        2 : without_mask\n    \"\"\"\n\nwith open('facemask.yaml', 'w') as f:\n    f.write(facemask_yaml)\n    \n%cat facemask.yaml","metadata":{"_uuid":"cde5f5d5-20fa-4cbb-97f7-271e0410971f","_cell_guid":"d7ec8110-8d6b-4315-b061-8c14bc827bf9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{"_uuid":"3da2efb4-eae8-4e44-a10a-665b2ef2cad0","_cell_guid":"7768d0ee-6a33-4431-91e3-b265ec0846f8","trusted":true}},{"cell_type":"markdown","source":"Building the model and setting up the requirments","metadata":{}},{"cell_type":"code","source":"model = YOLO(\"yolov8n.pt\") \nmodel.train(data=\"facemask.yaml\", epochs=10)","metadata":{"_uuid":"02e1de0b-07e6-46f2-aa58-4c8c998bcaa7","_cell_guid":"79f39251-7963-47ae-b827-752f94a3d3f2","collapsed":false,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.val(data=\"facemask.yaml\")","metadata":{"_uuid":"800bad7a-a13b-4eec-bfe0-7ae37b1bbd9a","_cell_guid":"6237d6ec-42cb-4ce3-8836-d257a1d1ec7f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Class names and corresponding metrics\nclass_names = ['with_mask', 'mask_weared_incorrect', 'without_mask', 'all']\nprecision = [0.915, 0.793, 0.765, 0.824]\nrecall = [0.838, 0.286, 0.713, 0.612]\nmAP50 = [0.91, 0.35, 0.721, 0.661]\nmAP50_95 = [0.575, 0.274, 0.439, 0.429]\n\n# Plot precision, recall, mAP50, mAP50-95\nplt.figure(figsize=(10, 6))\nplt.bar(class_names, precision, label='Precision', color='skyblue')\nplt.bar(class_names, recall, label='Recall', color='lightcoral')\nplt.bar(class_names, mAP50, label='mAP50', color='limegreen')\nplt.bar(class_names, mAP50_95, label='mAP50-95', color='orange')\nplt.xlabel('Class')\nplt.ylabel('Value')\nplt.title('YOLOv8 Evaluation Results')\nplt.legend()\nplt.xticks(rotation=45)\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"46abaefe-d362-42f9-967d-dce29087bb8d","_cell_guid":"2d88fe0f-e799-4620-9c69-b7c7375f9bfe","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Class names and corresponding metrics\nclass_names = ['with_mask', 'mask_weared_incorrect', 'without_mask', 'all']\nprecision = [0.915, 0.793, 0.765, 0.824]\nrecall = [0.838, 0.286, 0.713, 0.612]\nmAP50 = [0.91, 0.35, 0.721, 0.661]\nmAP50_95 = [0.575, 0.274, 0.439, 0.429]\n\n# Set the bar width\nbar_width = 0.2\n\n# Position of bars on the x-axis\nr1 = np.arange(len(class_names))\nr2 = [x + bar_width for x in r1]\nr3 = [x + bar_width for x in r2]\nr4 = [x + bar_width for x in r3]\n\n# Create the plot\nplt.figure(figsize=(10, 6))\nplt.bar(r1, precision, color='skyblue', width=bar_width, edgecolor='black', label='Precision')\nplt.bar(r2, recall, color='lightcoral', width=bar_width, edgecolor='black', label='Recall')\nplt.bar(r3, mAP50, color='limegreen', width=bar_width, edgecolor='black', label='mAP50')\nplt.bar(r4, mAP50_95, color='orange', width=bar_width, edgecolor='black', label='mAP50-95')\n\n# Add values above bars\nfor i, v in enumerate(precision):\n    plt.text(i - bar_width / 2, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(recall):\n    plt.text(i + bar_width / 2, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(mAP50):\n    plt.text(i + bar_width * 1.5, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(mAP50_95):\n    plt.text(i + bar_width * 2.5, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\n\n# Customize the plot\nplt.xlabel('Class')\nplt.ylabel('Value')\nplt.title('YOLOv8 Evaluation Results for 10 Epochs')\nplt.xticks([r + 1.5 * bar_width for r in range(len(class_names))], class_names)\nplt.legend(loc='upper left')\nplt.grid(axis='y')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"65d9b742-a69e-4158-a959-c6a1bd536897","_cell_guid":"9d70e73e-7db9-44bd-8df2-49d69cda5e89","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = YOLO(\"yolov8n.pt\") \nmodel1.train(data=\"facemask.yaml\", epochs=25)","metadata":{"_uuid":"8846e308-65bf-4282-8121-6b2471ce521c","_cell_guid":"b97bbf1f-5356-4df0-af51-faf560f1a65d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.val(data=\"facemask.yaml\")","metadata":{"_uuid":"5ad1648d-0c57-4ad4-95d0-f4853ae08be1","_cell_guid":"96b21140-6ed3-41f9-82ea-b02aeda0306d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Class names and corresponding metrics\nclass_names = ['with_mask', 'mask_weared_incorrect', 'without_mask', 'all']\nprecision = [0.945, 1.0, 0.822, 0.922]\nrecall = [0.856, 0.353, 0.695, 0.635]\nmAP50 = [0.937, 0.603, 0.732, 0.757]\nmAP50_95 = [0.601, 0.406, 0.434, 0.481]\n\n# Set the bar width\nbar_width = 0.2\n\n# Position of bars on the x-axis\nr1 = np.arange(len(class_names))\nr2 = [x + bar_width for x in r1]\nr3 = [x + bar_width for x in r2]\nr4 = [x + bar_width for x in r3]\n\n# Create the plot\nplt.figure(figsize=(10, 6))\nplt.bar(r1, precision, color='skyblue', width=bar_width, edgecolor='black', label='Precision')\nplt.bar(r2, recall, color='lightcoral', width=bar_width, edgecolor='black', label='Recall')\nplt.bar(r3, mAP50, color='limegreen', width=bar_width, edgecolor='black', label='mAP50')\nplt.bar(r4, mAP50_95, color='orange', width=bar_width, edgecolor='black', label='mAP50-95')\n\n# Add values above bars\nfor i, v in enumerate(precision):\n    plt.text(i - bar_width / 2, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(recall):\n    plt.text(i + bar_width / 2, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(mAP50):\n    plt.text(i + bar_width * 1.5, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(mAP50_95):\n    plt.text(i + bar_width * 2.5, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\n\n# Customize the plot\nplt.xlabel('Class')\nplt.ylabel('Value')\nplt.title('YOLOv8 Evaluation Results for 25 Epochs')\nplt.xticks([r + 1.5 * bar_width for r in range(len(class_names))], class_names)\nplt.legend(loc='upper left')\nplt.grid(axis='y')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"1d68f0cb-95e6-448d-97ec-ec5ce99c7d37","_cell_guid":"e0a3ca12-bb2f-4718-9420-7c5b8a18119a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = YOLO(\"yolov8n.pt\") \nmodel2.train(data=\"facemask.yaml\", epochs=40)","metadata":{"_uuid":"39e4a727-bafe-4f6f-964f-a3eec4847b15","_cell_guid":"2d0b1205-38e7-45c6-bac3-fb4b1dff76dc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.val(data=\"facemask.yaml\")","metadata":{"_uuid":"851d547a-a256-4f09-9f27-3b707eb099bb","_cell_guid":"a3109885-adcb-4dbf-b7f1-94801e81a1ad","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Class names and corresponding metrics\nclass_names = ['with_mask', 'mask_weared_incorrect', 'without_mask', 'all']\nprecision = [0.932, 0.744, 0.837, 0.838]\nrecall = [0.886, 0.714, 0.754, 0.784]\nmAP50 = [0.931, 0.7, 0.813, 0.815]\nmAP50_95 = [0.619, 0.471, 0.477, 0.522]\n\n# Set the bar width\nbar_width = 0.2\n\n# Position of bars on the x-axis\nr1 = np.arange(len(class_names))\nr2 = [x + bar_width for x in r1]\nr3 = [x + bar_width for x in r2]\nr4 = [x + bar_width for x in r3]\n\n# Create the plot\nplt.figure(figsize=(10, 6))\nplt.bar(r1, precision, color='skyblue', width=bar_width, edgecolor='black', label='Precision')\nplt.bar(r2, recall, color='lightcoral', width=bar_width, edgecolor='black', label='Recall')\nplt.bar(r3, mAP50, color='limegreen', width=bar_width, edgecolor='black', label='mAP50')\nplt.bar(r4, mAP50_95, color='orange', width=bar_width, edgecolor='black', label='mAP50-95')\n\n# Add values above bars\nfor i, v in enumerate(precision):\n    plt.text(i - bar_width / 2, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(recall):\n    plt.text(i + bar_width / 2, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(mAP50):\n    plt.text(i + bar_width * 1.5, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\nfor i, v in enumerate(mAP50_95):\n    plt.text(i + bar_width * 2.5, v + 0.02, str(round(v, 3)), color='black', ha='center', fontsize=8)\n\n# Customize the plot\nplt.xlabel('Class')\nplt.ylabel('Value')\nplt.title('YOLOv8 Evaluation Results for 40 Epochs')\nplt.xticks([r + 1.5 * bar_width for r in range(len(class_names))], class_names)\nplt.legend(loc='upper left')\nplt.grid(axis='y')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"00ea9886-98e2-4b25-ba93-738e7d52eb1e","_cell_guid":"5b91d509-794d-4f16-bb23-9619771a6b2b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{"_uuid":"48a559ac-7063-44f8-ab01-b62e669c8a1f","_cell_guid":"f9d76c50-a9c5-4e2e-8a1b-dfa6217c4fbf","trusted":true}},{"cell_type":"code","source":"confusion_matrix = Image.open(\"/kaggle/working/runs/detect/train/confusion_matrix.png\")\nplt.figure(figsize=(20,10))\nplt.imshow(confusion_matrix)\nplt.axis(False)\nplt.show()","metadata":{"_uuid":"ea58821b-3047-45e2-a88f-eba0eb7af367","_cell_guid":"c27e96c3-cb36-40e0-9332-7a3693fd107f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_label = Image.open(\"/kaggle/working/runs/detect/train/val_batch0_labels.jpg\")\nval_pred = Image.open(\"/kaggle/working/runs/detect/train/val_batch0_pred.jpg\")\n\nplt.figure(figsize=(20,10))\nplt.imshow(val_label)\nplt.title(\"Label\")\nplt.axis(False)\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.imshow(val_pred)\nplt.title(\"Prediction\")\nplt.axis(False)\nplt.show()","metadata":{"_uuid":"6ac0e127-cea4-4aea-9a0d-b792ca648d1c","_cell_guid":"520a89a2-b11c-46f6-89a1-bee0d5577023","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{"_uuid":"f31df1fc-9f4b-43ac-956a-f4ddef438cd9","_cell_guid":"e6fbdca2-0602-43e4-94e2-995fc38b00a9","trusted":true}},{"cell_type":"code","source":"model = YOLO(model=\"/kaggle/working/runs/detect/train/weights/best.pt\")","metadata":{"_uuid":"acf22765-7fe2-4845-8cf2-6cffe691272e","_cell_guid":"96b842aa-51b0-4fc9-ad67-a59e74e33958","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = glob.glob(test_path+\"/*.png\", recursive=False)\ntest_image1 = cv2.imread(filenames[0])\ntest_image2 = cv2.imread(filenames[1])\n\nresults = model.predict([test_image1, test_image2], save=True, line_thickness=1)","metadata":{"_uuid":"09c138e2-7412-41f4-95b5-dfc2141cb69e","_cell_guid":"3bf96c19-8977-4965-9ab1-22b0bbbe7e94","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_image = Image.open(\"runs/detect/predict/image0.jpg\")\nplt.figure(figsize=(10,10))\nplt.imshow(predicted_image)\nplt.title(\"Prediction\")\nplt.axis(False)\nplt.show()\n\npredicted_image = Image.open(\"runs/detect/predict/image1.jpg\")\nplt.figure(figsize=(10,10))\nplt.imshow(predicted_image)\nplt.title(\"Prediction\")\nplt.axis(False)\nplt.show()","metadata":{"_uuid":"eb2a0206-230f-4923-a601-e1cba34674f1","_cell_guid":"c10724d6-abea-4aff-a89b-b4cb91759aac","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"078fd6ad-79b6-4c28-8524-ac26743197df","_cell_guid":"8b240266-342e-4f76-8c36-33472ff68404","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"c2e0ff17-7ffc-4133-bc8e-3a9c59ad0f89","_cell_guid":"f48f987d-be33-4604-abd1-76da7c932bb4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"63e28ad8-c956-47cf-b247-7326f78b7609","_cell_guid":"4c42ec70-67b8-402c-9a79-85b15043da46","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"3eccde7d-b746-4097-8355-0dfda59ce086","_cell_guid":"f5b61452-6a8a-4c18-9753-09c344696ef5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"8c5aaa47-5833-4278-8ecb-772f8531fda4","_cell_guid":"02578ead-dc7d-461a-b39b-b67d72bb1a25","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"ead8ccb7-b9e3-4336-8cc9-547f3719aa53","_cell_guid":"3326cff4-841f-42c9-8056-94716051ceb5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}